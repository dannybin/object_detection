{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.60-cp38-cp38-macosx_10_15_x86_64.whl (45.9 MB)\n",
      "     |████████████████████████████████| 45.9 MB 2.0 MB/s            \n",
      "\u001b[?25hCollecting numpy>=1.17.3\n",
      "  Using cached numpy-1.21.4-cp38-cp38-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "Installing collected packages: numpy, opencv-python\n",
      "Successfully installed numpy-1.21.4 opencv-python-4.5.4.60\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import opencv\n",
    "import cv2 \n",
    "\n",
    "# Import uuid\n",
    "import uuid\n",
    "\n",
    "# Import Operating System\n",
    "import os\n",
    "\n",
    "# Import time\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.x Setup Connection to ActionCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: out device of bound (0-0): 1\n",
      "OpenCV: camera failed to properly initialize!\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('ActionCam Feed', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. Define Images to Collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['happy', 'sad', 'confused', 'angry']\n",
    "number_imgs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Setup Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('Tensorflow', 'object_detection', 'training_data', 'facialexpression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create file path based on above file path\n",
    "if not os.path.exists(IMAGES_PATH):\n",
    "    if os.name == 'posix':\n",
    "        !mkdir -p {IMAGES_PATH}\n",
    "    if os.name == 'nt':\n",
    "         !mkdir {IMAGES_PATH}\n",
    "for label in labels:\n",
    "    path = os.path.join(IMAGES_PATH, label)\n",
    "    if not os.path.exists(path):\n",
    "        !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Capture Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting images for happy\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for sad\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for confused\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n",
      "Collecting images for angry\n",
      "Collecting image 0\n",
      "Collecting image 1\n",
      "Collecting image 2\n",
      "Collecting image 3\n",
      "Collecting image 4\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    cap = cv2.VideoCapture(0) #connects to webcam or capture device\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    for imgnum in range(number_imgs):\n",
    "        print('Collecting image {}'.format(imgnum))\n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH,label,label+'.'+'{}.jpg'.format(str(uuid.uuid1())))\n",
    "        cv2.imwrite(imgname, frame)\n",
    "        cv2.imshow('frame', frame)\n",
    "        time.sleep(2)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Image Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqt5\n",
      "  Downloading PyQt5-5.15.6-cp36-abi3-macosx_10_13_x86_64.whl (7.0 MB)\n",
      "     |████████████████████████████████| 7.0 MB 1.7 MB/s            \n",
      "\u001b[?25hCollecting lxml\n",
      "  Using cached lxml-4.6.4-cp38-cp38-macosx_10_14_x86_64.whl (4.5 MB)\n",
      "Collecting PyQt5-Qt5>=5.15.2\n",
      "  Downloading PyQt5_Qt5-5.15.2-py3-none-macosx_10_13_intel.whl (40.5 MB)\n",
      "     |████████████████████████████████| 40.5 MB 1.1 MB/s            \n",
      "\u001b[?25hCollecting PyQt5-sip<13,>=12.8\n",
      "  Downloading PyQt5_sip-12.9.0-cp38-cp38-macosx_10_9_x86_64.whl (63 kB)\n",
      "     |████████████████████████████████| 63 kB 1.2 MB/s            \n",
      "\u001b[?25hInstalling collected packages: PyQt5-sip, PyQt5-Qt5, pyqt5, lxml\n",
      "Successfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.0 lxml-4.6.4 pyqt5-5.15.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELIMG_PATH = os.path.join('Tensorflow', 'facial_expression_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow/facial_expression_labels'...\n",
      "remote: Enumerating objects: 1923, done.\u001b[K\n",
      "remote: Counting objects: 100% (163/163), done.\u001b[K\n",
      "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
      "remote: Total 1923 (delta 78), reused 99 (delta 42), pack-reused 1760\u001b[K\n",
      "Receiving objects: 100% (1923/1923), 232.84 MiB | 2.73 MiB/s, done.\n",
      "Resolving deltas: 100% (1125/1125), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(LABELIMG_PATH):\n",
    "    !mkdir {LABELIMG_PATH}\n",
    "    !git clone https://github.com/tzutalin/labelImg {LABELIMG_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyrcc5 -o libs/resources.py resources.qrc\r\n"
     ]
    }
   ],
   "source": [
    "if os.name == 'posix':\n",
    "    !cd {LABELIMG_PATH} && make qt5py3\n",
    "if os.name =='nt':\n",
    "    !cd {LABELIMG_PATH} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelImg.py:965: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  bar.setValue(bar.value() + bar.singleStep() * units)\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2d885298-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2d885298-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2c50150a-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2c50150a-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2b18036e-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2b18036e-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2d885298-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.2d885298-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3bfb844a-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3bfb844a-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3d342952-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3d342952-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3e71516e-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3e71516e-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3fae2f98-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.3fae2f98-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.28a751ac-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.28a751ac-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.29dfef34-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/angry.29dfef34-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.29dfef34-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/angry.29dfef34-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.40e6efda-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/angry.40e6efda-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.1f7d4d8e-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.1f7d4d8e-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.40e6efda-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.40e6efda-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.29dfef34-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/angry/angry.29dfef34-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.20ba520a-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.20ba520a-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.21f242c2-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.21f242c2-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.37c0fc70-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.37c0fc70-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.340e90c4-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.340e90c4-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.2467b370-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.2467b370-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.232a7858-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.232a7858-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.32d1e210-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/confused/confused.32d1e210-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.0f9dc5d8-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.0f9dc5d8-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.10d622b0-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.10d622b0-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.21b644c6-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.21b644c6-56bf-11ec-a05f-44f09ea90161.xml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.22f206ea-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.22f206ea-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.242a1afc-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.242a1afc-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.20641f8a-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.20641f8a-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.256283dc-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.256283dc-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.12130936-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/happy/happy.12130936-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.1a00c688-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.1a00c688-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.1b3dbf1a-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.1b3dbf1a-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2adeb236-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2adeb236-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2c1c3b5a-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2c1c3b5a-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2d54e530-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2d54e530-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2e922840-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.2e922840-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.18c7e01c-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.18c7e01c-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.29a18e84-56bf-11ec-a05f-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.29a18e84-56bf-11ec-a05f-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.178fd8b2-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.178fd8b2-56c0-11ec-931b-44f09ea90161.xml\n",
      "Image:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.1652385a-56c0-11ec-931b-44f09ea90161.jpg -> Annotation:/Users/danielbin/Desktop/TFODCourse/Tensorflow/object_detection/training_data/facialexpression/sad/sad.1652385a-56c0-11ec-931b-44f09ea90161.xml\n"
     ]
    }
   ],
   "source": [
    "!cd {LABELIMG_PATH} && python labelImg.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Move them into a Training and Testing Partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL - 7. Compress them for Colab Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('Tensorflow', 'object_detection', 'training_data', 'train')\n",
    "TEST_PATH = os.path.join('Tensorflow', 'object_detection', 'training_data', 'test')\n",
    "ARCHIVE_PATH = os.path.join('Tensorflow', 'object_detection', 'training_data', 'archive.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf {ARCHIVE_PATH} {TRAIN_PATH} {TEST_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfod",
   "language": "python",
   "name": "tfod"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
